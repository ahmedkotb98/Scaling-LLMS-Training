# model params
base_model: unsloth/Meta-Llama-3.1-8B-Instruct

# dataset params
datasets:
  - path: TheFuzzyScientist/squad-for-llms
    type: 
      system_prompt: "Read the following context and concisely answer my question."
      field_system: system
      field_instruction: question
      field_input: context
      field_output: output
      format: "<|user|>\n {input} {instruction} </s>\n<|assistant|>"
      no_input_format: "<|user|> {instruction} </s>\n<|assistant|>"


output_dir: ./models/Llama3_squad


# model params
sequence_length: 2048
bf16: auto
tf32: false

# training params
micro_batch_size: 4
num_epochs: 4
optimizer: adamw_bnb_8bit
learning_rate: 0.0002

logging_steps: 1


# LoRA
adapter: lora

lora_r: 32
lora_alpha: 16
lora_dropout: 0.05

lora_target_linear: true

# Gradient Accumulation
gradient_accumulation_steps: 1

# Gradient Checkpointing
gradient_checkpointing: true